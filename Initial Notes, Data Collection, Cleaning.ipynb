{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource Awesome dataset\n",
    "\n",
    "Financial\n",
    "Weather\n",
    "Then biology predicting certain disease\n",
    "\n",
    "Main components of project  \n",
    "supervised learning: classification, SQL, flask, MVP and building outward\n",
    "\n",
    "VOICE MUSIC: DID I SING IT RIGHT OR HOW WELL DID I SING (KARAOKE MACHINES GRADING YOUR PERFORMANCE HOW?)\n",
    "Maybe me singing and grading it by an arbitrary algorithm?\n",
    "How to have it learn from the actual song and compare with my singing?\n",
    "Maybe classify if a note is correct or not.\n",
    "How to deal with rhythm though?\n",
    "Time the song and the transition of each note. \n",
    "Also how to deal with ad lib and spontaneous changes that work?\n",
    "This involves delving into image processing?\n",
    "\n",
    "MVP would be just something that finds if you hit the right note regardless of rhythm? Where is the machine learning in that though? Dont I just have to take the decibels in?\n",
    "then could add rhythm and maybe adlib\n",
    "\n",
    "might need to table this topic for later\n",
    "\n",
    "\n",
    "TYPHOON/HURRICANE CLASSIFICATION\n",
    "something to do with typhoons\n",
    "a huge super typhoon hit hong kong(my home) while I was there before the bootcamp started\n",
    "classify typhoon strength? what they do now is measure wind speed in order to classify or do they take satellite pictures in order to find wind speed? buoys are used?\n",
    "brief research shows that satellite images are now being used to estimate wind speeds. Buoys are definitely used. An article as late as 2016 still says pilots fly out to collect wind speed data.\n",
    "could probably get data from HK weather observatory? or do it for hurricanes in US?\n",
    "This requires delving into analyzing images.\n",
    "Maybe if a emergency response is needed? \n",
    "Trying to find the right complexity. \n",
    "\n",
    "# Financial Problem Statement 1\n",
    "Crypto currency winners or losers. Should all be losers at this point but could be recovering now? But relative to other cryptos I guess.\n",
    "![crypto](https://raw.githubusercontent.com/dynogravelso/mcnulty/master/crypto_ideas.JPG \"crypto ideas\")  \n",
    "Foreign currency exchange data. Easier to understand? Any country data?  \n",
    "Question 1: Funds Data and Stock Data. Making portfolio yourself vs. buying funds. There is probably more there than just which one is better right? Also isn't that more regression than classification?  \n",
    "Sharpe ratio or just mean/std\n",
    "\n",
    "# Weather Problem Statement 1\n",
    "![typhoon](https://raw.githubusercontent.com/dynogravelso/mcnulty/master/typhoon_ideas.JPG \"typhoon ideas\")\n",
    "Classify as Major/Minor/Not a big deal\n",
    "Features to find:\n",
    "Hurricane Data (Pressure, Eye diameter, Rain, Speed, Temp)\n",
    "Environment Data (Sea level, Global CO2 levels, Ice Cap, Weather)\n",
    "Data found: Monthly Average Temperature and Precipitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# convert names of files into list into text file\n",
    "# https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/\n",
    "with open('gzlist.txt') as f:\n",
    "    content = f.readlines()\n",
    "    fnames = [_.strip() for _ in content]\n",
    "    path = '/Users/dynogravelso/Documents/GitHub/mcnulty/'\n",
    "    fnames = [path+name for name in fnames]\n",
    "for fname in fnames:\n",
    "    print(fname)\n",
    "    !gunzip $fname\n",
    "    \n",
    "# /Users/dynogravelso/Documents/GitHub/mcnulty/StormEvents_details-ftp_v1.0_d1950_c20170120.csv.gz"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('gzlist.txt') as f:\n",
    "    content = f.readlines()\n",
    "    fnames = [_.strip().replace('.gz','') for _ in content]\n",
    "total_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fnames_details = fnames[0:69]\n",
    "fnames_fatalities = fnames[69:138]\n",
    "fnames_locations = fnames[138:207]\n",
    "fnames_total = [fnames_details, fnames_fatalities, fnames_locations]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# concat everything while reading from each csv\n",
    "total_df = [pd.DataFrame(),pd.DataFrame(),pd.DataFrame()]\n",
    "for i, fname_type in enumerate(fnames_total):        \n",
    "    for fname in fname_type:\n",
    "        if i == 0:\n",
    "            # assigning some dtypes to columns with warnings\n",
    "            one_df = pd.read_csv(fname, dtype = {'FLOOD_CAUSE': str, 'TOR_OTHER_WFO': str, 'TOR_OTHER_CZ_STATE': str, 'TOR_OTHER_CZ_NAME': str, 'SOURCE': str, 'MAGNITUDE_TYPE': str})\n",
    "            total_df[i] = pd.concat([total_df[i],one_df])\n",
    "#             print(str(fname))\n",
    "        else:\n",
    "            one_df = pd.read_csv(fname)\n",
    "            total_df[i] = pd.concat([total_df[i],one_df])\n",
    "#             print(str(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('all_storm_info' + '.pkl', 'wb') as picklefile:\n",
    "#     pickle.dump(total_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "total_df = pd.read_pickle('all_storm_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[2]['EVENT_ID'] = total_df[2]['EVENT_ID'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CZ_FIPS</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>DEATHS_INDIRECT</th>\n",
       "      <th>MAGNITUDE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TOR_LENGTH</th>\n",
       "      <th>TOR_WIDTH</th>\n",
       "      <th>TOR_OTHER_CZ_FIPS</th>\n",
       "      <th>BEGIN_RANGE</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.281946e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514184e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>1.514185e+06</td>\n",
       "      <td>892217.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>263265.000000</td>\n",
       "      <td>263265.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>819526.000000</td>\n",
       "      <td>819149.000000</td>\n",
       "      <td>936087.000000</td>\n",
       "      <td>936087.000000</td>\n",
       "      <td>758597.000000</td>\n",
       "      <td>758598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.003663e+05</td>\n",
       "      <td>1.499595e+01</td>\n",
       "      <td>1.326502e+03</td>\n",
       "      <td>2.003663e+05</td>\n",
       "      <td>1.633056e+01</td>\n",
       "      <td>1.486190e+03</td>\n",
       "      <td>6.579533e+05</td>\n",
       "      <td>3.709782e+06</td>\n",
       "      <td>3.164434e+01</td>\n",
       "      <td>2.003604e+03</td>\n",
       "      <td>9.355019e+01</td>\n",
       "      <td>9.960011e-02</td>\n",
       "      <td>8.441505e-03</td>\n",
       "      <td>1.173503e-02</td>\n",
       "      <td>1.528215e-03</td>\n",
       "      <td>25.120205</td>\n",
       "      <td>1.375940</td>\n",
       "      <td>0.865781</td>\n",
       "      <td>31.020770</td>\n",
       "      <td>104.719403</td>\n",
       "      <td>2.367046</td>\n",
       "      <td>2.303580</td>\n",
       "      <td>37.844888</td>\n",
       "      <td>-92.620687</td>\n",
       "      <td>37.904947</td>\n",
       "      <td>-92.747085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.158240e+03</td>\n",
       "      <td>9.094419e+00</td>\n",
       "      <td>6.671332e+02</td>\n",
       "      <td>1.158240e+03</td>\n",
       "      <td>9.102727e+00</td>\n",
       "      <td>6.032086e+02</td>\n",
       "      <td>7.501498e+05</td>\n",
       "      <td>3.574978e+06</td>\n",
       "      <td>1.710111e+01</td>\n",
       "      <td>1.158302e+01</td>\n",
       "      <td>1.094920e+02</td>\n",
       "      <td>4.014830e+00</td>\n",
       "      <td>2.060941e+00</td>\n",
       "      <td>6.390916e-01</td>\n",
       "      <td>5.860460e-02</td>\n",
       "      <td>36.501246</td>\n",
       "      <td>0.960358</td>\n",
       "      <td>8.107986</td>\n",
       "      <td>124.059144</td>\n",
       "      <td>83.616096</td>\n",
       "      <td>6.190648</td>\n",
       "      <td>4.712186</td>\n",
       "      <td>4.898166</td>\n",
       "      <td>34.638207</td>\n",
       "      <td>4.922463</td>\n",
       "      <td>38.065567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.950010e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.950010e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.950000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.400000</td>\n",
       "      <td>-815.100000</td>\n",
       "      <td>-14.456000</td>\n",
       "      <td>-815.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.999010e+05</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>1.999010e+05</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.200000e+03</td>\n",
       "      <td>5.616800e+04</td>\n",
       "      <td>4.000790e+05</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.999000e+03</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>-97.610000</td>\n",
       "      <td>34.570000</td>\n",
       "      <td>-97.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.006060e+05</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.517000e+03</td>\n",
       "      <td>2.006060e+05</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.615000e+03</td>\n",
       "      <td>1.130000e+05</td>\n",
       "      <td>5.149453e+06</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.006000e+03</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.980000</td>\n",
       "      <td>-91.550000</td>\n",
       "      <td>38.050000</td>\n",
       "      <td>-91.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.012050e+05</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.820000e+03</td>\n",
       "      <td>2.012050e+05</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.910000e+03</td>\n",
       "      <td>1.167428e+06</td>\n",
       "      <td>5.577620e+06</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>2.012000e+03</td>\n",
       "      <td>1.170000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.350000</td>\n",
       "      <td>-83.680000</td>\n",
       "      <td>41.380000</td>\n",
       "      <td>-83.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.018070e+05</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.359000e+03</td>\n",
       "      <td>2.018070e+05</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.359000e+03</td>\n",
       "      <td>2.414827e+06</td>\n",
       "      <td>1.035852e+07</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.018000e+03</td>\n",
       "      <td>8.760000e+02</td>\n",
       "      <td>1.700000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>6.380000e+02</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>22000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2315.000000</td>\n",
       "      <td>4576.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>3749.000000</td>\n",
       "      <td>925.000000</td>\n",
       "      <td>70.502900</td>\n",
       "      <td>171.400000</td>\n",
       "      <td>70.434200</td>\n",
       "      <td>171.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEGIN_YEARMONTH     BEGIN_DAY    BEGIN_TIME  END_YEARMONTH  \\\n",
       "count     1.514185e+06  1.514185e+06  1.514185e+06   1.514185e+06   \n",
       "mean      2.003663e+05  1.499595e+01  1.326502e+03   2.003663e+05   \n",
       "std       1.158240e+03  9.094419e+00  6.671332e+02   1.158240e+03   \n",
       "min       1.950010e+05  1.000000e+00  0.000000e+00   1.950010e+05   \n",
       "25%       1.999010e+05  7.000000e+00  9.000000e+02   1.999010e+05   \n",
       "50%       2.006060e+05  1.500000e+01  1.517000e+03   2.006060e+05   \n",
       "75%       2.012050e+05  2.300000e+01  1.820000e+03   2.012050e+05   \n",
       "max       2.018070e+05  3.100000e+01  2.359000e+03   2.018070e+05   \n",
       "\n",
       "            END_DAY      END_TIME    EPISODE_ID      EVENT_ID    STATE_FIPS  \\\n",
       "count  1.514185e+06  1.514185e+06  1.281946e+06  1.514185e+06  1.514184e+06   \n",
       "mean   1.633056e+01  1.486190e+03  6.579533e+05  3.709782e+06  3.164434e+01   \n",
       "std    9.102727e+00  6.032086e+02  7.501498e+05  3.574978e+06  1.710111e+01   \n",
       "min    1.000000e+00  0.000000e+00  1.000000e+00  3.000000e+00  1.000000e+00   \n",
       "25%    8.000000e+00  1.200000e+03  5.616800e+04  4.000790e+05  1.900000e+01   \n",
       "50%    1.600000e+01  1.615000e+03  1.130000e+05  5.149453e+06  3.000000e+01   \n",
       "75%    2.400000e+01  1.910000e+03  1.167428e+06  5.577620e+06  4.500000e+01   \n",
       "max    3.100000e+01  2.359000e+03  2.414827e+06  1.035852e+07  9.900000e+01   \n",
       "\n",
       "               YEAR       CZ_FIPS  INJURIES_DIRECT  INJURIES_INDIRECT  \\\n",
       "count  1.514185e+06  1.514185e+06     1.514185e+06       1.514185e+06   \n",
       "mean   2.003604e+03  9.355019e+01     9.960011e-02       8.441505e-03   \n",
       "std    1.158302e+01  1.094920e+02     4.014830e+00       2.060941e+00   \n",
       "min    1.950000e+03  0.000000e+00     0.000000e+00       0.000000e+00   \n",
       "25%    1.999000e+03  2.500000e+01     0.000000e+00       0.000000e+00   \n",
       "50%    2.006000e+03  6.500000e+01     0.000000e+00       0.000000e+00   \n",
       "75%    2.012000e+03  1.170000e+02     0.000000e+00       0.000000e+00   \n",
       "max    2.018000e+03  8.760000e+02     1.700000e+03       2.400000e+03   \n",
       "\n",
       "       DEATHS_DIRECT  DEATHS_INDIRECT      MAGNITUDE    CATEGORY  \\\n",
       "count   1.514185e+06     1.514185e+06  892217.000000  266.000000   \n",
       "mean    1.173503e-02     1.528215e-03      25.120205    1.375940   \n",
       "std     6.390916e-01     5.860460e-02      36.501246    0.960358   \n",
       "min     0.000000e+00     0.000000e+00       0.000000    1.000000   \n",
       "25%     0.000000e+00     0.000000e+00       0.880000    1.000000   \n",
       "50%     0.000000e+00     0.000000e+00       1.750000    1.000000   \n",
       "75%     0.000000e+00     0.000000e+00      52.000000    1.000000   \n",
       "max     6.380000e+02     2.000000e+01   22000.000000    5.000000   \n",
       "\n",
       "          TOR_LENGTH      TOR_WIDTH  TOR_OTHER_CZ_FIPS    BEGIN_RANGE  \\\n",
       "count  263265.000000  263265.000000        2010.000000  819526.000000   \n",
       "mean        0.865781      31.020770         104.719403       2.367046   \n",
       "std         8.107986     124.059144          83.616096       6.190648   \n",
       "min         0.000000       0.000000           1.000000       0.000000   \n",
       "25%         0.000000       0.000000          47.000000       0.000000   \n",
       "50%         0.000000       0.000000          93.000000       1.000000   \n",
       "75%         0.000000      10.000000         139.000000       3.000000   \n",
       "max      2315.000000    4576.000000         810.000000    3749.000000   \n",
       "\n",
       "           END_RANGE      BEGIN_LAT      BEGIN_LON        END_LAT  \\\n",
       "count  819149.000000  936087.000000  936087.000000  758597.000000   \n",
       "mean        2.303580      37.844888     -92.620687      37.904947   \n",
       "std         4.712186       4.898166      34.638207       4.922463   \n",
       "min         0.000000     -14.400000    -815.100000     -14.456000   \n",
       "25%         0.000000      34.400000     -97.610000      34.570000   \n",
       "50%         1.000000      37.980000     -91.550000      38.050000   \n",
       "75%         3.000000      41.350000     -83.680000      41.380000   \n",
       "max       925.000000      70.502900     171.400000      70.434200   \n",
       "\n",
       "             END_LON  \n",
       "count  758598.000000  \n",
       "mean      -92.747085  \n",
       "std        38.065567  \n",
       "min      -815.100000  \n",
       "25%       -97.500000  \n",
       "50%       -91.080000  \n",
       "75%       -83.270000  \n",
       "max       171.400000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1233592 entries, 0 to 37060\n",
      "Data columns (total 11 columns):\n",
      "YEARMONTH         1233592 non-null object\n",
      "EPISODE_ID        1233592 non-null object\n",
      "EVENT_ID          1233592 non-null int64\n",
      "LOCATION_INDEX    1233592 non-null object\n",
      "RANGE             805483 non-null float64\n",
      "AZIMUTH           805483 non-null object\n",
      "LOCATION          1035654 non-null object\n",
      "LATITUDE          971922 non-null float64\n",
      "LONGITUDE         971922 non-null float64\n",
      "LAT2              761185 non-null float64\n",
      "LON2              761185 non-null float64\n",
      "dtypes: float64(5), int64(1), object(5)\n",
      "memory usage: 112.9+ MB\n"
     ]
    }
   ],
   "source": [
    "total_df[2].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKING A COMPLETE COMBINED dataframe\n",
    "full_df = pd.merge(total_df[0], total_df[1], how = 'outer', on='EVENT_ID')\n",
    "full_df = pd.merge(full_df, total_df[2], how = 'outer', on='EVENT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1782715 entries, 0 to 1782714\n",
      "Data columns (total 71 columns):\n",
      "BEGIN_YEARMONTH       1782692 non-null float64\n",
      "BEGIN_DAY             1782692 non-null float64\n",
      "BEGIN_TIME            1782692 non-null float64\n",
      "END_YEARMONTH         1782692 non-null float64\n",
      "END_DAY               1782692 non-null float64\n",
      "END_TIME              1782692 non-null float64\n",
      "EPISODE_ID_x          1550453 non-null float64\n",
      "EVENT_ID              1782715 non-null int64\n",
      "STATE                 1782691 non-null object\n",
      "STATE_FIPS            1782691 non-null float64\n",
      "YEAR                  1782692 non-null float64\n",
      "MONTH_NAME            1782692 non-null object\n",
      "EVENT_TYPE            1782692 non-null object\n",
      "CZ_TYPE               1782692 non-null object\n",
      "CZ_FIPS               1782692 non-null float64\n",
      "CZ_NAME               1781135 non-null object\n",
      "WFO                   1657122 non-null object\n",
      "BEGIN_DATE_TIME       1782692 non-null object\n",
      "CZ_TIMEZONE           1782692 non-null object\n",
      "END_DATE_TIME         1782692 non-null object\n",
      "INJURIES_DIRECT       1782692 non-null float64\n",
      "INJURIES_INDIRECT     1782692 non-null float64\n",
      "DEATHS_DIRECT         1782692 non-null float64\n",
      "DEATHS_INDIRECT       1782692 non-null float64\n",
      "DAMAGE_PROPERTY       1263109 non-null object\n",
      "DAMAGE_CROPS          1143812 non-null object\n",
      "SOURCE                1436356 non-null object\n",
      "MAGNITUDE             925281 non-null float64\n",
      "MAGNITUDE_TYPE        370900 non-null object\n",
      "FLOOD_CAUSE           279092 non-null object\n",
      "CATEGORY              306 non-null float64\n",
      "TOR_F_SCALE           85406 non-null object\n",
      "TOR_LENGTH            282052 non-null float64\n",
      "TOR_WIDTH             282052 non-null float64\n",
      "TOR_OTHER_WFO         4984 non-null object\n",
      "TOR_OTHER_CZ_STATE    4984 non-null object\n",
      "TOR_OTHER_CZ_FIPS     4984 non-null float64\n",
      "TOR_OTHER_CZ_NAME     4984 non-null object\n",
      "BEGIN_RANGE           1076247 non-null float64\n",
      "BEGIN_AZIMUTH         857527 non-null object\n",
      "BEGIN_LOCATION        1116077 non-null object\n",
      "END_RANGE             1075836 non-null float64\n",
      "END_AZIMUTH           844412 non-null object\n",
      "END_LOCATION          1076721 non-null object\n",
      "BEGIN_LAT             1199904 non-null float64\n",
      "BEGIN_LON             1199904 non-null float64\n",
      "END_LAT               1022414 non-null float64\n",
      "END_LON               1022415 non-null float64\n",
      "EPISODE_NARRATIVE     1292266 non-null object\n",
      "EVENT_NARRATIVE       954718 non-null object\n",
      "DATA_SOURCE           1782692 non-null object\n",
      "FAT_YEARMONTH         21881 non-null float64\n",
      "FAT_DAY               21881 non-null float64\n",
      "FAT_TIME              21881 non-null float64\n",
      "FATALITY_ID           21881 non-null float64\n",
      "FATALITY_TYPE         21881 non-null object\n",
      "FATALITY_DATE         21871 non-null object\n",
      "FATALITY_AGE          18934 non-null float64\n",
      "FATALITY_SEX          19835 non-null object\n",
      "FATALITY_LOCATION     20482 non-null object\n",
      "EVENT_YEARMONTH       21862 non-null float64\n",
      "YEARMONTH             1240291 non-null object\n",
      "EPISODE_ID_y          1240291 non-null object\n",
      "LOCATION_INDEX        1240291 non-null object\n",
      "RANGE                 809321 non-null float64\n",
      "AZIMUTH               809321 non-null object\n",
      "LOCATION              1039887 non-null object\n",
      "LATITUDE              975768 non-null float64\n",
      "LONGITUDE             975768 non-null float64\n",
      "LAT2                  764646 non-null float64\n",
      "LON2                  764646 non-null float64\n",
      "dtypes: float64(36), int64(1), object(34)\n",
      "memory usage: 979.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# full_df.info(verbose = True, null_counts = True)\n",
    "# full_df.describe()\n",
    "# full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('complete_df' + '.pkl', 'wb') as picklefile:\n",
    "#     pickle.dump(full_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-87543aa69423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'complete'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         libwriters.write_csv_rows(self.data, ix, self.nlevels,\n\u001b[0;32m--> 313\u001b[0;31m                                   self.cols, self.writer)\n\u001b[0m",
      "\u001b[0;32mpandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# full_df.to_csv('complete', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_needed = list(full_df.columns)\n",
    "columns_needed = ['BEGIN_YEARMONTH',\n",
    " 'BEGIN_DAY',\n",
    " 'BEGIN_TIME',\n",
    " 'EVENT_ID',\n",
    " 'STATE',\n",
    " 'YEAR',\n",
    " 'MONTH_NAME',\n",
    " 'EVENT_TYPE',\n",
    " 'INJURIES_DIRECT',\n",
    " 'INJURIES_INDIRECT',\n",
    " 'DEATHS_DIRECT',\n",
    " 'DEATHS_INDIRECT',\n",
    " 'DAMAGE_PROPERTY',\n",
    " 'DAMAGE_CROPS',\n",
    " 'MAGNITUDE',\n",
    " 'MAGNITUDE_TYPE',\n",
    " 'BEGIN_LAT',\n",
    " 'BEGIN_LON',\n",
    " 'END_LAT',\n",
    " 'END_LON',\n",
    " 'FAT_YEARMONTH',\n",
    " 'FAT_DAY',\n",
    " 'FAT_TIME',\n",
    " 'FATALITY_ID',\n",
    " 'FATALITY_AGE',\n",
    " 'FATALITY_SEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1782715 entries, 0 to 1782714\n",
      "Data columns (total 71 columns):\n",
      "BEGIN_YEARMONTH       1782692 non-null float64\n",
      "BEGIN_DAY             1782692 non-null float64\n",
      "BEGIN_TIME            1782692 non-null float64\n",
      "END_YEARMONTH         1782692 non-null float64\n",
      "END_DAY               1782692 non-null float64\n",
      "END_TIME              1782692 non-null float64\n",
      "EPISODE_ID_x          1550453 non-null float64\n",
      "EVENT_ID              1782715 non-null int64\n",
      "STATE                 1782691 non-null object\n",
      "STATE_FIPS            1782691 non-null float64\n",
      "YEAR                  1782692 non-null float64\n",
      "MONTH_NAME            1782692 non-null object\n",
      "EVENT_TYPE            1782692 non-null object\n",
      "CZ_TYPE               1782692 non-null object\n",
      "CZ_FIPS               1782692 non-null float64\n",
      "CZ_NAME               1781135 non-null object\n",
      "WFO                   1657122 non-null object\n",
      "BEGIN_DATE_TIME       1782692 non-null object\n",
      "CZ_TIMEZONE           1782692 non-null object\n",
      "END_DATE_TIME         1782692 non-null object\n",
      "INJURIES_DIRECT       1782692 non-null float64\n",
      "INJURIES_INDIRECT     1782692 non-null float64\n",
      "DEATHS_DIRECT         1782692 non-null float64\n",
      "DEATHS_INDIRECT       1782692 non-null float64\n",
      "DAMAGE_PROPERTY       1263109 non-null object\n",
      "DAMAGE_CROPS          1143812 non-null object\n",
      "SOURCE                1436356 non-null object\n",
      "MAGNITUDE             925281 non-null float64\n",
      "MAGNITUDE_TYPE        370900 non-null object\n",
      "FLOOD_CAUSE           279092 non-null object\n",
      "CATEGORY              306 non-null float64\n",
      "TOR_F_SCALE           85406 non-null object\n",
      "TOR_LENGTH            282052 non-null float64\n",
      "TOR_WIDTH             282052 non-null float64\n",
      "TOR_OTHER_WFO         4984 non-null object\n",
      "TOR_OTHER_CZ_STATE    4984 non-null object\n",
      "TOR_OTHER_CZ_FIPS     4984 non-null float64\n",
      "TOR_OTHER_CZ_NAME     4984 non-null object\n",
      "BEGIN_RANGE           1076247 non-null float64\n",
      "BEGIN_AZIMUTH         857527 non-null object\n",
      "BEGIN_LOCATION        1116077 non-null object\n",
      "END_RANGE             1075836 non-null float64\n",
      "END_AZIMUTH           844412 non-null object\n",
      "END_LOCATION          1076721 non-null object\n",
      "BEGIN_LAT             1199904 non-null float64\n",
      "BEGIN_LON             1199904 non-null float64\n",
      "END_LAT               1022414 non-null float64\n",
      "END_LON               1022415 non-null float64\n",
      "EPISODE_NARRATIVE     1292266 non-null object\n",
      "EVENT_NARRATIVE       954718 non-null object\n",
      "DATA_SOURCE           1782692 non-null object\n",
      "FAT_YEARMONTH         21881 non-null float64\n",
      "FAT_DAY               21881 non-null float64\n",
      "FAT_TIME              21881 non-null float64\n",
      "FATALITY_ID           21881 non-null float64\n",
      "FATALITY_TYPE         21881 non-null object\n",
      "FATALITY_DATE         21871 non-null object\n",
      "FATALITY_AGE          18934 non-null float64\n",
      "FATALITY_SEX          19835 non-null object\n",
      "FATALITY_LOCATION     20482 non-null object\n",
      "EVENT_YEARMONTH       21862 non-null float64\n",
      "YEARMONTH             1240291 non-null object\n",
      "EPISODE_ID_y          1240291 non-null object\n",
      "LOCATION_INDEX        1240291 non-null object\n",
      "RANGE                 809321 non-null float64\n",
      "AZIMUTH               809321 non-null object\n",
      "LOCATION              1039887 non-null object\n",
      "LATITUDE              975768 non-null float64\n",
      "LONGITUDE             975768 non-null float64\n",
      "LAT2                  764646 non-null float64\n",
      "LON2                  764646 non-null float64\n",
      "dtypes: float64(36), int64(1), object(34)\n",
      "memory usage: 979.3+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info(verbose=True, null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1782715 entries, 0 to 1782714\n",
      "Data columns (total 26 columns):\n",
      "BEGIN_YEARMONTH      1782692 non-null float64\n",
      "BEGIN_DAY            1782692 non-null float64\n",
      "BEGIN_TIME           1782692 non-null float64\n",
      "EVENT_ID             1782715 non-null int64\n",
      "STATE                1782691 non-null object\n",
      "YEAR                 1782692 non-null float64\n",
      "MONTH_NAME           1782692 non-null object\n",
      "EVENT_TYPE           1782692 non-null object\n",
      "INJURIES_DIRECT      1782692 non-null float64\n",
      "INJURIES_INDIRECT    1782692 non-null float64\n",
      "DEATHS_DIRECT        1782692 non-null float64\n",
      "DEATHS_INDIRECT      1782692 non-null float64\n",
      "DAMAGE_PROPERTY      1263109 non-null object\n",
      "DAMAGE_CROPS         1143812 non-null object\n",
      "MAGNITUDE            925281 non-null float64\n",
      "MAGNITUDE_TYPE       370900 non-null object\n",
      "BEGIN_LAT            1199904 non-null float64\n",
      "BEGIN_LON            1199904 non-null float64\n",
      "END_LAT              1022414 non-null float64\n",
      "END_LON              1022415 non-null float64\n",
      "FAT_YEARMONTH        21881 non-null float64\n",
      "FAT_DAY              21881 non-null float64\n",
      "FAT_TIME             21881 non-null float64\n",
      "FATALITY_ID          21881 non-null float64\n",
      "FATALITY_AGE         18934 non-null float64\n",
      "FATALITY_SEX         19835 non-null object\n",
      "dtypes: float64(18), int64(1), object(7)\n",
      "memory usage: 367.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clean1_df = full_df[columns_needed]\n",
    "clean1_df.info(verbose=True, null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_types = list(full_df.EVENT_TYPE.unique())\n",
    "event_types\n",
    "event_types_wanted = [\n",
    " 'Thunderstorm Wind',\n",
    " 'THUNDERSTORM WINDS/FLOODING',\n",
    " 'THUNDERSTORM WINDS/FLASH FLOOD',\n",
    " 'THUNDERSTORM WINDS LIGHTNING',\n",
    " 'THUNDERSTORM WIND/ TREES',\n",
    " 'THUNDERSTORM WIND/ TREE',\n",
    " 'THUNDERSTORM WINDS FUNNEL CLOU',\n",
    " 'THUNDERSTORM WINDS/HEAVY RAIN',\n",
    " 'THUNDERSTORM WINDS HEAVY RAIN',\n",
    " 'THUNDERSTORM WINDS/ FLOOD',\n",
    " 'High Wind',\n",
    " 'Strong Wind',\n",
    " 'Tropical Storm',\n",
    " 'Hurricane (Typhoon)',\n",
    " 'Marine High Wind',\n",
    " 'Marine Thunderstorm Wind',\n",
    " 'Heavy Wind',\n",
    " 'Marine Strong Wind',\n",
    " 'Tropical Depression',\n",
    " 'Hurricane',\n",
    " 'Marine Tropical Storm',\n",
    " 'Marine Hurricane/Typhoon',\n",
    " 'Marine Tropical Depression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_df = clean1_df[clean1_df.EVENT_TYPE.isin(event_types_wanted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH_NAME</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>DEATHS_INDIRECT</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>MAGNITUDE</th>\n",
       "      <th>MAGNITUDE_TYPE</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>FAT_YEARMONTH</th>\n",
       "      <th>FAT_DAY</th>\n",
       "      <th>FAT_TIME</th>\n",
       "      <th>FATALITY_ID</th>\n",
       "      <th>FATALITY_AGE</th>\n",
       "      <th>FATALITY_SEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>195506.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>9976778</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>June</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "      <td>-86.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>195507.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>9976780</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>July</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.58</td>\n",
       "      <td>-86.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>195510.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>9976786</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>October</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.58</td>\n",
       "      <td>-86.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>195503.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>10005140</td>\n",
       "      <td>INDIANA</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>March</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.00</td>\n",
       "      <td>-85.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>195505.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>10000327</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>May</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "      <td>-85.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  EVENT_ID    STATE    YEAR  \\\n",
       "1867         195506.0       10.0      1500.0   9976778  ALABAMA  1955.0   \n",
       "1869         195507.0       28.0      1500.0   9976780  ALABAMA  1955.0   \n",
       "1874         195510.0       28.0      1640.0   9976786  ALABAMA  1955.0   \n",
       "1881         195503.0        3.0      2100.0  10005140  INDIANA  1955.0   \n",
       "1883         195505.0       15.0      1400.0  10000327  GEORGIA  1955.0   \n",
       "\n",
       "     MONTH_NAME         EVENT_TYPE  INJURIES_DIRECT  INJURIES_INDIRECT  \\\n",
       "1867       June  Thunderstorm Wind              0.0                0.0   \n",
       "1869       July  Thunderstorm Wind              0.0                0.0   \n",
       "1874    October  Thunderstorm Wind              0.0                0.0   \n",
       "1881      March  Thunderstorm Wind              0.0                0.0   \n",
       "1883        May  Thunderstorm Wind              0.0                0.0   \n",
       "\n",
       "      DEATHS_DIRECT  DEATHS_INDIRECT DAMAGE_PROPERTY DAMAGE_CROPS  MAGNITUDE  \\\n",
       "1867            0.0              0.0               0            0        0.0   \n",
       "1869            0.0              0.0               0            0       52.0   \n",
       "1874            0.0              0.0               0            0        0.0   \n",
       "1881            0.0              0.0               0            0        0.0   \n",
       "1883            0.0              0.0               0            0        0.0   \n",
       "\n",
       "     MAGNITUDE_TYPE  BEGIN_LAT  BEGIN_LON  END_LAT  END_LON  FAT_YEARMONTH  \\\n",
       "1867            NaN      33.00     -86.78      NaN      NaN            NaN   \n",
       "1869            NaN      33.58     -86.78      NaN      NaN            NaN   \n",
       "1874            NaN      33.58     -86.78      NaN      NaN            NaN   \n",
       "1881            NaN      41.00     -85.18      NaN      NaN            NaN   \n",
       "1883            NaN      33.00     -85.00      NaN      NaN            NaN   \n",
       "\n",
       "      FAT_DAY  FAT_TIME  FATALITY_ID  FATALITY_AGE FATALITY_SEX  \n",
       "1867      NaN       NaN          NaN           NaN          NaN  \n",
       "1869      NaN       NaN          NaN           NaN          NaN  \n",
       "1874      NaN       NaN          NaN           NaN          NaN  \n",
       "1881      NaN       NaN          NaN           NaN          NaN  \n",
       "1883      NaN       NaN          NaN           NaN          NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 568137 entries, 1867 to 1782691\n",
      "Data columns (total 26 columns):\n",
      "BEGIN_YEARMONTH      568137 non-null float64\n",
      "BEGIN_DAY            568137 non-null float64\n",
      "BEGIN_TIME           568137 non-null float64\n",
      "EVENT_ID             568137 non-null int64\n",
      "STATE                568137 non-null object\n",
      "YEAR                 568137 non-null float64\n",
      "MONTH_NAME           568137 non-null object\n",
      "EVENT_TYPE           568137 non-null object\n",
      "INJURIES_DIRECT      568137 non-null float64\n",
      "INJURIES_INDIRECT    568137 non-null float64\n",
      "DEATHS_DIRECT        568137 non-null float64\n",
      "DEATHS_INDIRECT      568137 non-null float64\n",
      "DAMAGE_PROPERTY      428893 non-null object\n",
      "DAMAGE_CROPS         354876 non-null object\n",
      "MAGNITUDE            518682 non-null float64\n",
      "MAGNITUDE_TYPE       370838 non-null object\n",
      "BEGIN_LAT            447389 non-null float64\n",
      "BEGIN_LON            447389 non-null float64\n",
      "END_LAT              356463 non-null float64\n",
      "END_LON              356464 non-null float64\n",
      "FAT_YEARMONTH        3205 non-null float64\n",
      "FAT_DAY              3205 non-null float64\n",
      "FAT_TIME             3205 non-null float64\n",
      "FATALITY_ID          3205 non-null float64\n",
      "FATALITY_AGE         2657 non-null float64\n",
      "FATALITY_SEX         2860 non-null object\n",
      "dtypes: float64(18), int64(1), object(7)\n",
      "memory usage: 117.0+ MB\n"
     ]
    }
   ],
   "source": [
    "wind_df.info(verbose=True, null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH_NAME</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>DEATHS_INDIRECT</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>MAGNITUDE</th>\n",
       "      <th>MAGNITUDE_TYPE</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>FAT_YEARMONTH</th>\n",
       "      <th>FAT_DAY</th>\n",
       "      <th>FAT_TIME</th>\n",
       "      <th>FATALITY_ID</th>\n",
       "      <th>FATALITY_AGE</th>\n",
       "      <th>FATALITY_SEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>540972</th>\n",
       "      <td>200203.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>5287381</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>March</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587845</th>\n",
       "      <td>200307.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>5334823</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>July</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>EG</td>\n",
       "      <td>33.77</td>\n",
       "      <td>-84.4</td>\n",
       "      <td>33.83</td>\n",
       "      <td>-84.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683871</th>\n",
       "      <td>200409.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>5421108</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>September</td>\n",
       "      <td>Tropical Storm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624929</th>\n",
       "      <td>200309.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>5370967</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>September</td>\n",
       "      <td>Tropical Storm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631151</th>\n",
       "      <td>200311.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>5371814</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>November</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>EG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  EVENT_ID         STATE  \\\n",
       "540972         200203.0        9.0      1152.0   5287381      ILLINOIS   \n",
       "587845         200307.0       10.0      1615.0   5334823       GEORGIA   \n",
       "683871         200409.0        4.0      2100.0   5421108       FLORIDA   \n",
       "624929         200309.0       18.0       900.0   5370967      VIRGINIA   \n",
       "631151         200311.0       13.0       500.0   5371814  PENNSYLVANIA   \n",
       "\n",
       "          YEAR MONTH_NAME         EVENT_TYPE  INJURIES_DIRECT  \\\n",
       "540972  2002.0      March          High Wind              4.0   \n",
       "587845  2003.0       July  Thunderstorm Wind              0.0   \n",
       "683871  2004.0  September     Tropical Storm              0.0   \n",
       "624929  2003.0  September     Tropical Storm              0.0   \n",
       "631151  2003.0   November          High Wind              0.0   \n",
       "\n",
       "        INJURIES_INDIRECT  DEATHS_DIRECT  DEATHS_INDIRECT DAMAGE_PROPERTY  \\\n",
       "540972                0.0            4.0              0.0            200K   \n",
       "587845                0.0            3.0              0.0             35K   \n",
       "683871                0.0            3.0              0.0             NaN   \n",
       "624929                0.0            2.0              0.0              9M   \n",
       "631151                0.0            2.0              0.0             NaN   \n",
       "\n",
       "       DAMAGE_CROPS  MAGNITUDE MAGNITUDE_TYPE  BEGIN_LAT  BEGIN_LON  END_LAT  \\\n",
       "540972          NaN       50.0              M        NaN        NaN      NaN   \n",
       "587845          NaN       53.0             EG      33.77      -84.4    33.83   \n",
       "683871          NaN        NaN            NaN        NaN        NaN      NaN   \n",
       "624929          NaN        NaN            NaN        NaN        NaN      NaN   \n",
       "631151          NaN       60.0             EG        NaN        NaN      NaN   \n",
       "\n",
       "        END_LON  FAT_YEARMONTH  FAT_DAY  FAT_TIME  FATALITY_ID  FATALITY_AGE  \\\n",
       "540972      NaN            NaN      NaN       NaN          NaN           NaN   \n",
       "587845   -84.37            NaN      NaN       NaN          NaN           NaN   \n",
       "683871      NaN            NaN      NaN       NaN          NaN           NaN   \n",
       "624929      NaN            NaN      NaN       NaN          NaN           NaN   \n",
       "631151      NaN            NaN      NaN       NaN          NaN           NaN   \n",
       "\n",
       "       FATALITY_SEX  \n",
       "540972          NaN  \n",
       "587845          NaN  \n",
       "683871          NaN  \n",
       "624929          NaN  \n",
       "631151          NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_df[wind_df.FATALITY_ID.isnull()].sort_values(by = 'DEATHS_DIRECT', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('wind_df' + '.pkl', 'wb') as picklefile:\n",
    "#     pickle.dump(wind_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cn_pr_df = pd.read_excel('cn_pr_1991_2015.xls')\n",
    "cn_tas_df = pd.read_excel('cn_tas_1991_2015.xls')\n",
    "us_pr_df = pd.read_excel('us_pr_1901_2015.xls')\n",
    "us_tas_df = pd.read_excel('us_tas_1901_2015.xls')\n",
    "# us_tas_df.sort_values(by = '\\tYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tas', '\\tYear', ' Month', ' Country', ' ISO3', ' ISO2'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_tas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column into datetime\n",
    "date_list = []\n",
    "for i in range(0,1380):\n",
    "    us_tas_df.iloc[i,4] = datetime(us_tas_df.iloc[i,1], us_tas_df.iloc[i,2],1).date()\n",
    "us_tas_df.rename(columns = {' ISO3': 'BEGIN_YEARMONTH'}, inplace = True)\n",
    "us_tas_df.drop(columns = ['\\tYear', ' Month', ' ISO2'], inplace = True)\n",
    "\n",
    "date_list = []\n",
    "for i in range(0,1380):\n",
    "    us_pr_df.iloc[i,4] = datetime(us_pr_df.iloc[i,1], us_pr_df.iloc[i,2],1).date() \n",
    "us_pr_df.rename(columns = {' ISO3': 'BEGIN_YEARMONTH'}, inplace = True)\n",
    "us_pr_df.drop(columns = ['\\tYear', ' Month', ' ISO2'], inplace = True)\n",
    "\n",
    "# us_tas_df['BEGIN_YEARMONTH'] = datetime(us_tas_df['\\tYear'], us_tas_df[' Month']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tas</th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.41530</td>\n",
       "      <td>1901-01-01</td>\n",
       "      <td>39.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.34610</td>\n",
       "      <td>1901-02-01</td>\n",
       "      <td>41.2308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.14910</td>\n",
       "      <td>1901-03-01</td>\n",
       "      <td>47.1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.00631</td>\n",
       "      <td>1901-04-01</td>\n",
       "      <td>49.7707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.18910</td>\n",
       "      <td>1901-05-01</td>\n",
       "      <td>53.2810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tas BEGIN_YEARMONTH       pr\n",
       "0  -5.41530      1901-01-01  39.7591\n",
       "1  -6.34610      1901-02-01  41.2308\n",
       "2  -0.14910      1901-03-01  47.1593\n",
       "3   5.00631      1901-04-01  49.7707\n",
       "4  12.18910      1901-05-01  53.2810"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_df = pd.merge(us_tas_df, us_pr_df, how = 'inner', on='BEGIN_YEARMONTH')\n",
    "us_df.drop(columns = [' Country_y',' Country_x'], inplace = True)\n",
    "climate_df = us_df\n",
    "climate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('climate_df' + '.pkl', 'wb') as picklefile:\n",
    "#     pickle.dump(climate_df, picklefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
